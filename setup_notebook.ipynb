{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/numba/compiler.py:602: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"numba_utilities7.py\", line 296:\n",
      "@njit(signature0,parallel=True)\n",
      "def erf_times_gauss_numba0(x):\n",
      "^\n",
      "\n",
      "  self.func_ir.loc))\n",
      "/home/thijs/repos/dnp-code/PGM7/numba_utilities7.py:703: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, A), array(float32, 2d, A))\n",
      "  mean_V = np.dot(weights,V)/sum_weights\n",
      "/home/thijs/repos/dnp-code/PGM7/numba_utilities7.py:862: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dmean_v_dw = np.dot(s1.T,V)\n",
      "/home/thijs/repos/dnp-code/PGM7/numba_utilities7.py:863: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dvar_e_dw = np.dot(s2.T,V)\n",
      "/home/thijs/repos/dnp-code/PGM7/numba_utilities7.py:864: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  tmp3 = np.dot(s3.T,V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1109: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dmean_v_dw = np.dot(s1.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1110: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dvar_e_dw = np.dot(s2.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1111: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  tmp3 = np.dot(s3.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:946: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, A), array(float32, 2d, A))\n",
      "  mean_V = np.dot(weights, V) / sum_weights\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "# from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "#                                                   mark_inset)\n",
    "import sys,os\n",
    "import importlib\n",
    "# from multiprocessing.dummy import Pool as ThreadPool\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import dReLU_Regression\n",
    "import Gaussian_Regression\n",
    "import scipy.fftpack\n",
    "# import xarray as xr\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.tsa.api import VAR\n",
    "from tqdm import tqdm\n",
    "import scipy.io\n",
    "curr_dir = os.getcwd()\n",
    "# os.chdir('/home/thijs/repos/fishualizer/')\n",
    "# from utilities import Zecording\n",
    "# import pipeline_functions as fish_pf\n",
    "os.chdir('/home/thijs/repos/dnp-code/PGM7/')\n",
    "import rbm7\n",
    "import utilities7 as utilities\n",
    "import pickle\n",
    "import rbm7_trackprogress\n",
    "import rbm7_trackprogress_wb\n",
    "os.chdir('/home/thijs/repos/dnp-code/PGM3_correct/source/')\n",
    "import rbm\n",
    "from fishualizer_utilities import Zecording\n",
    "os.chdir(curr_dir)\n",
    "import rbm_pipeline_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot settings\n",
    "\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Dejavu Sans'\n",
    "plt.rcParams['font.style'] = 'normal'\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "dr_colors = {'glm': '#008B8B', 'pca': '#808000', 'rbm': '#800080', 'fa': 'red', 'ica':'#157bf9'}\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color'] # default color cycle\n",
    "\n",
    "\n",
    "dr_legend = {'pca': 'PCA', 'rbm': 'RBM', 'fa': 'FA', 'ica': 'ICA', 'glm': 'GLM'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "baseline with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "drifts with shape (5553, 2) is not recognized, so it cannot be loaded.\n",
      "inferredspikes with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "ljpcoordinates with shape (3, 54334) is not recognized, so it cannot be loaded.\n",
      "segmentation with shape (30, 598, 1280) is not recognized, so it cannot be loaded.\n",
      "temporalmean with shape (30, 598, 1280) is not recognized, so it cannot be loaded.\n",
      "rawsignal with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "trace with shape (5553, 1) is not recognized, so it cannot be loaded.\n",
      "metadata with shape (1, 1) is not recognized, so it cannot be loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording from /home/thijs/Desktop/20180912_Run01_spontaneous_rbm2.h5\n"
     ]
    }
   ],
   "source": [
    "base_path = '/home/thijs/Desktop/'\n",
    "data_sets = {#'20180912-Run01': '20180912_Run01Tset=.h5'}\n",
    "            '20180912-Run01': '20180912_Run01_spontaneous_rbm2.h5'}#,\n",
    "\n",
    "## Load data\n",
    "\n",
    "time_cutoff_end = 4000 # hard coded for now\n",
    "# time_cutoffs = {''}\n",
    "recordings = {}\n",
    "for data_set, data_path in data_sets.items():\n",
    "    recordings[data_set] = Zecording(path=base_path + data_path, kwargs={'ignorelags': True,\n",
    "                                              'forceinterpolation': False,\n",
    "                                              'ignoreunknowndata': True,# 'parent': self,\n",
    "                                              'loadram': True})  # load data\n",
    "rec = recordings['20180912-Run01']\n",
    "# rec = recordings['2019-03-26(Run09)']\n",
    "print(rec)\n",
    "regions = {#'rh1': np.array([218]), 'rhall': np.array([113]),\n",
    "          'wb': np.arange(294)}\n",
    "selected_neurons = {}\n",
    "n_sel_cells = {}\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "full_data = {}\n",
    "train_times = rec.times[:time_cutoff_end]\n",
    "test_times = rec.times[time_cutoff_end:]\n",
    "\n",
    "for ir in list(regions.keys()):\n",
    "    selected_neurons[ir] = np.unique(scipy.sparse.find(rec.labels[:, regions[ir]])[0])\n",
    "    n_sel_cells[ir] = len(selected_neurons[ir])\n",
    "    train_data[ir] = rec.spikes[selected_neurons[ir], :time_cutoff_end]\n",
    "    test_data[ir] = rec.spikes[selected_neurons[ir], time_cutoff_end:]\n",
    "    full_data[ir] = rec.spikes[selected_neurons[ir], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_wb = np.unique(scipy.sparse.find(rec.labels[:, np.arange(294)])[0])\n",
    "# inds_rhall = np.unique(scipy.sparse.find(rec.labels[:, 113])[0])\n",
    "# inds_rh1_of_all = scipy.sparse.find(rec.labels[:, 218])[0]\n",
    "# inds_rh1 = np.arange(len(np.unique(scipy.sparse.find(rec.labels[:, 218])[0])))\n",
    "# inds_rh1_of_wb = scipy.sparse.find(rec.labels[inds_wb, 218])[0]\n",
    "# inds_rh1_of_rhall = scipy.sparse.find(rec.labels[inds_rhall, 218])[0]\n",
    "# inds_rhall_of_wb = scipy.sparse.find(rec.labels[inds_wb, 113])[0]\n",
    "# np.median(llh_array['2019-05-10-2036'][inds_rh1_of_rhall])\n",
    "\n",
    "# inds_rh1_all = {'rh1': inds_rh1, 'rhall': inds_rh1_of_rhall, 'wb': inds_rh1_of_wb}\n",
    "# inds_all_dict = {'rh1': inds_rh1, 'rhall': inds_rhall, 'wb': inds_wb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction not burst: 0.892670628489105\n"
     ]
    }
   ],
   "source": [
    "# selected_neurons = scipy.sparse.find(rec.labels[:, 218])[0]\n",
    "tmp_reg = 'wb'\n",
    "\n",
    "population_rate = np.sum(rec.spikes[selected_neurons[tmp_reg], :], axis=0)\n",
    "sorted_pr = np.sort(population_rate)\n",
    "pr_coords = np.vstack((range(len(population_rate)), sorted_pr)).T\n",
    "first_point = pr_coords[0, :]\n",
    "line_vector = pr_coords[-1, :] - first_point\n",
    "line_vector_norm = line_vector / np.sqrt(np.sum(line_vector ** 2))\n",
    "vector_fromfirst = pr_coords - first_point\n",
    "# take vector product of vector_fromfirst * line_vector_norm to get parallel vector:\n",
    "scalar_product = np.sum(vector_fromfirst * \n",
    "                        np.matlib.repmat(line_vector_norm, len(population_rate), 1), axis=1)\n",
    "# now find perpendicular vector:\n",
    "vector_fromfirst_par = np.outer(scalar_product, line_vector_norm)\n",
    "vector_to_line = vector_fromfirst - vector_fromfirst_par\n",
    "distance_to_line = np.sqrt(np.sum(vector_to_line ** 2, axis=1))\n",
    "\n",
    "burst_cutoff = sorted_pr[np.argmax(distance_to_line)]\n",
    "pop_rate_train = np.sum(rec.spikes[selected_neurons[tmp_reg], :time_cutoff_end], axis=0)\n",
    "ind_train_wo_bursts = pop_rate_train <= burst_cutoff\n",
    "pop_rate_test = np.sum(rec.spikes[selected_neurons[tmp_reg], time_cutoff_end:], axis=0)\n",
    "ind_test_wo_bursts = pop_rate_test <= burst_cutoff\n",
    "pop_rate_full = np.sum(rec.spikes[selected_neurons[tmp_reg], :], axis=0)\n",
    "ind_full_wo_bursts = pop_rate_full <= burst_cutoff\n",
    "# print(burst_cutoff)\n",
    "print(f'Fraction not burst: {np.sum(population_rate <= burst_cutoff) / len(population_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08770326364294147"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burst_cutoff / len(selected_neurons['wb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
