{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/thijs/repos/dnp-code/PGM3_correct/source/')\n",
    "sys.path.append('/home/thijs/repos/dnp-code/PGM3_correct/utilities/')\n",
    "sys.path.append('PGM3_correct/source/') # the path where the folder PGM is.\n",
    "sys.path.append('PGM3_correct/utilities/') # the path where the folder PGM is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1109: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dmean_v_dw = np.dot(s1.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1110: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dvar_e_dw = np.dot(s2.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1111: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  tmp3 = np.dot(s3.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:946: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, A), array(float32, 2d, A))\n",
      "  mean_V = np.dot(weights, V) / sum_weights\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py, os\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import rbm as rbm\n",
    "from fishualizer_utilities import Zecording\n",
    "\n",
    "def export_weights_for_fishualizer(weights, recording=None, \n",
    "                                   labeled_cells_only=True,\n",
    "                                   path_weights='/home/thijs/',\n",
    "                                   filename_weights='weights_RBM-name.h5',\n",
    "                                   save_h5=True):\n",
    "    '''Export weights from RBM to file compatible with fishualizer viewing.\n",
    "    \n",
    "    Parameters:\n",
    "    ---------\n",
    "        rbm: RBM class\n",
    "            RBM object with weights to be exported\n",
    "        recording: Zecording class\n",
    "            Zecording object (from Fishualizer) that contains zebrafish data recording on which this rbm has been trained'\n",
    "        labeled_cells_only: bool\n",
    "            If the RBM has been trained on the Zbrain Atlas-labeled cells only; then we need to account for this when exporting the weights\n",
    "        path_weights: str\n",
    "            folder \n",
    "        filename_weights: str\n",
    "            file name \n",
    "    '''\n",
    "    \n",
    "    if filename_weights[-3:] != '.h5':\n",
    "        filename_weights = filename_weights + '.h5'\n",
    "        \n",
    "    ## Extract RBM weights:\n",
    "    # weights = np.transpose(rbm.weights) \n",
    "    assert weights.ndim == 2\n",
    "    assert weights.shape[0] > weights.shape[1], 'Weights should be neurons x HUs'\n",
    "    print(weights.shape)\n",
    "    \n",
    "    ## Take care of unlabeled cells if needed\n",
    "    if labeled_cells_only:\n",
    "        assert recording != None, 'the zebrafish recording is needed to account for labeled cells only weights'\n",
    "        n_cells = recording.n_cells\n",
    "        selected_neurons = np.unique(scipy.sparse.find(recording.labels[:, np.arange(294)])[0])  # cells with zbrain label\n",
    "        assert weights.shape[0] == len(selected_neurons)  # make sure shape is neurons x time (RBM has only used labelled neurons)\n",
    "        print(f'n cells: {n_cells}, n labelled cells: {len(selected_neurons)}')\n",
    "        full_weights = np.zeros((n_cells, weights.shape[1]), dtype='float32')  # make matrix for all cells (including non-labeled)\n",
    "        full_weights[selected_neurons, :] = weights  # let non-labelled neurons have w=0 for all HU\n",
    "    else:\n",
    "        print('Assuming that all cells were used for RBM training')\n",
    "        full_weights = weights.copy()\n",
    "        \n",
    "    ## Export to h5 via pd DataFrame\n",
    "    df_weights = pd.DataFrame({'hu_' + str(ii).zfill(3):\n",
    "                                np.squeeze(full_weights[:, ii]) for ii in range(full_weights.shape[1])})  # save as pd df with each column = one weight vector\n",
    "    if save_h5:\n",
    "        df_weights.to_hdf(os.path.join(path_weights, filename_weights), key='all')  # store as h5 file\n",
    "\n",
    "    ## To view the weights in the Fishualizer: \n",
    "    ## Launch the Fishualizer\n",
    "    ## Load the main data set (= rec) using File -> Open data\n",
    "    ## Load the saved weights (= df_weights) using File -> Add static data -> Choose Dataset\n",
    "        \n",
    "    return df_weights\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use the function above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/thijs/Desktop/zf_rbm_essentials/'\n",
    "# base_path = '/media/thijs/hooghoudt/Zebrafish_data/spontaneous_data_guillaume/'\n",
    "data_sets = {#'20180912-Run01': '20180912_Run01Tset=.h5'}\n",
    "            '20180912-Run01': '20180912_Run01_spontaneous_rbm2.h5'}#,\n",
    "test_segs = '267'\n",
    "train_inds_path=f'/home/thijs/repos/dnp-code/train_test_inds/20180912-Run01/train_test_inds__test_segs_{test_segs}_nseg10.pkl'  # HARD SET TO 10TH PERCENTILE OF 20180912-RUN01 (TEST SEGS 267)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "baseline with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "drifts with shape (5553, 2) is not recognized, so it cannot be loaded.\n",
      "inferredspikes with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "ljpcoordinates with shape (3, 54334) is not recognized, so it cannot be loaded.\n",
      "segmentation with shape (30, 598, 1280) is not recognized, so it cannot be loaded.\n",
      "temporalmean with shape (30, 598, 1280) is not recognized, so it cannot be loaded.\n",
      "rawsignal with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "trace with shape (5553, 1) is not recognized, so it cannot be loaded.\n",
      "metadata with shape (1, 1) is not recognized, so it cannot be loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording from /home/thijs/Desktop/zf_rbm_essentials/20180912_Run01_spontaneous_rbm2.h5\n",
      "len test inds 1665\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "## Load data\n",
    "recordings = {}\n",
    "for data_set, data_path in data_sets.items():\n",
    "    recordings[data_set] = Zecording(path=base_path + data_path, kwargs={'ignorelags': True,\n",
    "                                              'forceinterpolation': False,\n",
    "                                              'ignoreunknowndata': True,# 'parent': self,\n",
    "                                              'loadram': True})  # load data\n",
    "rec = recordings[list(data_sets.keys())[0]]\n",
    "# rec = recordings['2019-03-26(Run09)']\n",
    "print(rec)\n",
    "regions = {#'rh1': np.array([218]), 'rhall': np.array([113]),\n",
    "          'wb': np.arange(294)}\n",
    "selected_neurons = {}\n",
    "n_sel_cells = {}\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "full_data = {}\n",
    "\n",
    "dict_tt_inds = pickle.load(open(train_inds_path, 'rb'))  # load dictionary with training indices\n",
    "train_inds = dict_tt_inds['train_inds']  # load training inds, note that: # test_inds = dict_tt_inds['test_inds']\n",
    "test_inds = dict_tt_inds['test_inds']\n",
    "print(f'len test inds {len(test_inds)}')\n",
    "for ir in list(regions.keys()):\n",
    "    selected_neurons[ir] = np.unique(scipy.sparse.find(rec.labels[:, regions[ir]])[0])\n",
    "    assert rec.spikes.shape[0] > rec.spikes.shape[1]\n",
    "    train_data[ir] = rec.spikes[selected_neurons[ir], :][:, train_inds]\n",
    "    test_data[ir] = rec.spikes[selected_neurons[ir], :][:, test_inds]\n",
    "    n_sel_cells[ir] = len(selected_neurons[ir])\n",
    "    full_data[ir] = rec.spikes[selected_neurons[ir], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export 1 RBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/200 HU weights are flipped\n",
      "Flipped HUs are: (array([  1,  11,  12,  19,  30,  36,  37,  38,  41,  43,  52,  55,  67,\n",
      "        68,  70,  72,  88,  94,  95,  99, 100, 107, 111, 117, 118, 120,\n",
      "       124, 128, 133, 136, 138, 140, 151, 152, 167, 170, 171, 172, 175,\n",
      "       177, 181, 186, 188, 191, 198]),)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/home/thijs/repos/zf-rbm/figure_notebooks')\n",
    "import swap_sign_RBM as ssrbm\n",
    "rbm_path = '/home/thijs/Desktop/zf_rbm_essentials/RBM3_20180912-Run01-spontaneous-rbm2_wb_test-segs-267-nseg10_M200_l1-2e-02_duration208093s_timestamp2020-05-16-0844.data'\n",
    "hu_assert = [1,  11,  12,  19,  30,  36,  37,  38,  41,  43,  52,  55,  67, 68,  70,  72,  88,  94,  95,  99, 100, 107, 111, 117, 118, 120, 124, 128, 133, 136, 138, 140, 151, 152, 167, 170, 171, 172, 175, 177, 181, 186, 188, 191, 198]  # HUs that sholud be swapped\n",
    "tmp_RBM = pickle.load(open(rbm_path, 'rb'))\n",
    "RBM = ssrbm.swap_sign_RBM(RBM=tmp_RBM, verbose=2, assert_hu_inds=hu_assert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52518, 200)\n",
      "n cells: 54334, n labelled cells: 52518\n"
     ]
    }
   ],
   "source": [
    "tmp_df = export_weights_for_fishualizer(weights=RBM.weights.T, recording=rec, \n",
    "                                   labeled_cells_only=True,\n",
    "                                   path_weights='/home/thijs/',\n",
    "                                   filename_weights='weights_RBM-name2',\n",
    "                                   save_h5=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42704743"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.iloc[200].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export multiple RBMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/home/thijs/repos/zf-rbm/figure_notebooks')\n",
    "import swap_sign_RBM as ssrbm\n",
    "import analysis_functions as af\n",
    "\n",
    "all_rbm_paths = af.rbm_paths_used_for_sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/thijs/hooghoudt/new_sweep_april20/RBM_sweep_combined/weights/\n"
     ]
    }
   ],
   "source": [
    "m_cond_str = 'M200_'\n",
    "l_cond_str = 'l1-2e-02'\n",
    "list_rbm_sel = [x for x in all_rbm_paths if m_cond_str in x and l_cond_str in x]\n",
    "assert len(list_rbm_sel) == 1, list_rbm_sel\n",
    "rbm_sel_path = list_rbm_sel[0]\n",
    "weight_path = os.path.join('/'.join(rbm_sel_path.split('/')[:-1]), 'weights/')\n",
    "weights_fn = 'weights_' + rbm_sel_path.split('/')[-1].rstrip('.data') + '_signswapped' + '.h5'\n",
    "print(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/100 HU weights are flipped\n",
      "Flipped HUs are: (array([ 0,  1,  2,  4,  5,  6,  8,  9, 10, 11, 12, 13, 15, 17, 18, 19, 20,\n",
      "       22, 24, 27, 28, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45,\n",
      "       46, 47, 51, 52, 53, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69,\n",
      "       70, 71, 73, 77, 79, 81, 82, 84, 86, 87, 88, 89, 90, 92, 93, 94, 97,\n",
      "       99]),)\n",
      "(52518, 100)\n",
      "n cells: 54334, n labelled cells: 52518\n"
     ]
    }
   ],
   "source": [
    "rbm_path = rbm_sel_path\n",
    "# hu_assert = [1,  11,  12,  19,  30,  36,  37,  38,  41,  43,  52,  55,  67, 68,  70,  72,  88,  94,  95,  99, 100, 107, 111, 117, 118, 120, 124, 128, 133, 136, 138, 140, 151, 152, 167, 170, 171, 172, 175, 177, 181, 186, 188, 191, 198]  # HUs that sholud be swapped\n",
    "tmp_RBM = pickle.load(open(rbm_path, 'rb'))\n",
    "RBM = ssrbm.swap_sign_RBM(RBM=tmp_RBM, verbose=2, assert_hu_inds=None)\n",
    "tmp_df = export_weights_for_fishualizer(weights=RBM.weights.T, recording=rec, \n",
    "                                   labeled_cells_only=True,\n",
    "                                   path_weights=weight_path,\n",
    "                                   filename_weights=weights_fn,\n",
    "                                   save_h5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export VAE weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = None\n",
    "RBM = None \n",
    "env = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 52518)\n"
     ]
    }
   ],
   "source": [
    "vae_results_path = '/home/thijs/Google Drive/projects/ZF RBM; M_Internship/VAE/VAE_results_2.data'\n",
    "env = pickle.load(open(vae_results_path,'rb'))\n",
    "print(env['W'].shape)\n",
    "env['spikes_train'] = None \n",
    "env['reconstruction_spikes'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52518, 300)\n",
      "n cells: 54334, n labelled cells: 52518\n"
     ]
    }
   ],
   "source": [
    "tmp_df = export_weights_for_fishualizer(weights=env['W'].T, recording=rec, \n",
    "                                   labeled_cells_only=True,\n",
    "                                   path_weights='/home/thijs/Google Drive/projects/ZF RBM; M_Internship/VAE/',\n",
    "                                   filename_weights='weights_VAE_M300_l1e-2',\n",
    "                                   save_h5=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3c6bff6b69abaf96a90d989026a9cf294704cfb600e1a0547450741192dbe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
