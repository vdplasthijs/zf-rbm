{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1109: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dmean_v_dw = np.dot(s1.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1110: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  dvar_e_dw = np.dot(s2.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:1111: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, F), array(float32, 2d, A))\n",
      "  tmp3 = np.dot(s3.T, V)\n",
      "/home/thijs/repos/dnp-code/PGM3_correct/source/numba_utilities.py:946: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, A), array(float32, 2d, A))\n",
      "  mean_V = np.dot(weights, V) / sum_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thijs/repos/dnp-code/rbm_pipeline_functions.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/.conda/envs/py37/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "baseline with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "drifts with shape (5553, 2) is not recognized, so it cannot be loaded.\n",
      "inferredspikes with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "ljpcoordinates with shape (3, 54334) is not recognized, so it cannot be loaded.\n",
      "segmentation with shape (30, 598, 1280) is not recognized, so it cannot be loaded.\n",
      "temporalmean with shape (30, 598, 1280) is not recognized, so it cannot be loaded.\n",
      "rawsignal with shape (5553, 54334) is not recognized, so it cannot be loaded.\n",
      "trace with shape (5553, 1) is not recognized, so it cannot be loaded.\n",
      "metadata with shape (1, 1) is not recognized, so it cannot be loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording from /home/thijs/Desktop/zf_rbm_essentials/20180912_Run01_spontaneous_rbm2.h5\n",
      "len test inds 1665\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%run setup_notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/thijs/repos/zf-rbm/figure_notebooks/')\n",
    "import plotting_functions as pf\n",
    "import analysis_functions as af\n",
    "import swap_sign_RBM as ssrbm\n",
    "pf.set_fontsize(font_size=12)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load annotation files\n",
    "dir_path = '/home/thijs/repos/zf-rbm/figures/HU_info_2020-05-16-0844/sign-swapped'\n",
    "annot_file = 'Volker_HU_manual_annotation_2020-11-27_signswapped.txt'\n",
    "annot_file_path = os.path.join(dir_path, annot_file)\n",
    "\n",
    "new_dir = '/home/thijs/repos/zf-rbm/figures/HU_info_2020-05-16-0844/correlation-sorted_sign-swapped'\n",
    "new_annot_file ='Volker_HU_manual_annotation_2020-11-27_correlation-sorted_signswapped.txt'\n",
    "\n",
    "with open(annot_file_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "new_content = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/200 HU weights are flipped\n",
      "Flipped HUs are: (array([  1,  11,  12,  19,  30,  36,  37,  38,  41,  43,  52,  55,  67,\n",
      "        68,  70,  72,  88,  94,  95,  99, 100, 107, 111, 117, 118, 120,\n",
      "       124, 128, 133, 136, 138, 140, 151, 152, 167, 170, 171, 172, 175,\n",
      "       177, 181, 186, 188, 191, 198]),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thijs/repos/dnp-code/PGM3_correct/source/layer.py:1152: RuntimeWarning: overflow encountered in true_divide\n",
      "  ) / (etg_plus / np.sqrt(self._gamma_plus)))\n"
     ]
    }
   ],
   "source": [
    "## Used for non sign swapped to sign swapped\n",
    "# ## Load RBM\n",
    "# rbm_path = '/media/thijs/hooghoudt/new_sweep_april20/RBM_sweep_reruns/RBM3_20180912-Run01-spontaneous-rbm2_wb_test-segs-267-nseg10_M200_l1-2e-02_duration208093s_timestamp2020-05-16-0844.data'\n",
    "# RBM_dict = {'old': pickle.load(open(rbm_path, 'rb'))}\n",
    "# RBM_dict['signswapped'] = ssrbm.swap_sign_RBM(RBM=RBM_dict['old'], verbose=2)\n",
    "\n",
    "# ## two mappings\n",
    "# hu_act_test, hu_act_test_remap, ol = {}, {}, {}\n",
    "# for key, RBM in RBM_dict.items():\n",
    "#     hu_act_test[key] = np.transpose(RBM.mean_hiddens(test_data['wb'].T))\n",
    "#     ol[key] = af.opt_leaf(hu_act_test[key])\n",
    "#     hu_act_test_remap[key] = hu_act_test[key][ol[key], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/200 HU weights are flipped\n",
      "Flipped HUs are: (array([  1,  11,  12,  19,  30,  36,  37,  38,  41,  43,  52,  55,  67,\n",
      "        68,  70,  72,  88,  94,  95,  99, 100, 107, 111, 117, 118, 120,\n",
      "       124, 128, 133, 136, 138, 140, 151, 152, 167, 170, 171, 172, 175,\n",
      "       177, 181, 186, 188, 191, 198]),)\n",
      "OPTIMAL LEAF SOSRTING AND EUCLIDEAN USED\n"
     ]
    }
   ],
   "source": [
    "## Used for sign swapped to correlation sorted\n",
    "## Load RBM\n",
    "rbm_path = '/media/thijs/hooghoudt/new_sweep_april20/RBM_sweep_reruns/RBM3_20180912-Run01-spontaneous-rbm2_wb_test-segs-267-nseg10_M200_l1-2e-02_duration208093s_timestamp2020-05-16-0844.data'\n",
    "tmp_RBM = pickle.load(open(rbm_path, 'rb'))\n",
    "RBM = ssrbm.swap_sign_RBM(RBM=tmp_RBM, verbose=2)\n",
    "\n",
    "## two mappings\n",
    "hu_act_test, hu_act_test_remap, ol = {}, {}, {}\n",
    "for key, metric in {'old': 'euclidean', 'cs': 'correlation'}.items():\n",
    "    hu_act_test[key] = np.transpose(RBM.mean_hiddens(test_data['wb'].T))\n",
    "    ol[key], tmp = af.opt_leaf(hu_act_test[key], link_metric=metric)\n",
    "    hu_act_test_remap[key] = hu_act_test[key][ol[key], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## align mappings:\n",
    "nhu = 200\n",
    "old_mapping = np.zeros((nhu, 2))\n",
    "i_hu = 0\n",
    "for new_index, old_index in enumerate(ol['old']):\n",
    "    old_mapping[i_hu, 0] = old_index\n",
    "    old_mapping[i_hu, 1] = new_index\n",
    "    i_hu += 1\n",
    "tmp_inds_sorted = np.argsort(old_mapping[:, 0])\n",
    "old_mapping_sorted = old_mapping[tmp_inds_sorted, :]\n",
    "\n",
    "signswapped_mapping = np.zeros((nhu, 2))\n",
    "i_hu = 0\n",
    "for new_index, old_index in enumerate(ol['cs']): # enumerate(ol['signswapped']):\n",
    "    signswapped_mapping[i_hu, 0] = old_index\n",
    "    signswapped_mapping[i_hu, 1] = new_index\n",
    "    i_hu += 1\n",
    "tmp_inds_sorted = np.argsort(signswapped_mapping[:, 0])\n",
    "signswapped_mapping_sorted = signswapped_mapping[tmp_inds_sorted, :]\n",
    "    \n",
    "translation_old_ol_to_new_ol = {}\n",
    "for i_nhu in range(nhu):\n",
    "    translation_old_ol_to_new_ol[int(old_mapping_sorted[i_nhu, 1])] = int(signswapped_mapping_sorted[i_nhu, 1])\n",
    "    \n",
    "assert translation_old_ol_to_new_ol[86] == signswapped_mapping_sorted[ol['old'][86], 1]  # check for random hU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old': array([176,  34, 156,  29,  68, 141, 109, 119, 195, 175,  30,  50,  54,\n",
       "        135,  39, 129,   6,   7,  80, 167, 164, 187, 113,  72, 143, 120,\n",
       "        169, 145, 197,  10,   8, 144,  64,  11, 181, 170,  13, 125, 165,\n",
       "        114, 103,  85,  73,  77,  63,  83,  87, 184, 110,  98, 137,  90,\n",
       "         41,  38, 127, 146,  23, 105,   2, 153, 148, 194, 130, 121, 142,\n",
       "         24, 172, 182,  93,  15, 149,  53, 117,  61, 115,  19, 180, 185,\n",
       "         57,  62, 151, 189, 178,  51,  16, 133,   9,  60,  74, 101,  84,\n",
       "         59,  47, 190,  31,  95,  94,  92,  81,  91,  35,   4,  48,  58,\n",
       "        111,  67, 131,  18,   3, 183, 118, 126, 173,  20,  25,  45,  86,\n",
       "        166,  79,  33,  69,  49,  26,  52,  22,  14, 163,  97, 112, 198,\n",
       "         88, 162,  28, 188,  99, 102, 140, 100, 161,   5, 136,   0, 108,\n",
       "        186,  21,  55, 168, 191,  89,  37, 192,  66, 174, 154,  82,  65,\n",
       "         56, 159, 122, 124,  17, 104,  70, 152, 139,  78, 160,  42,  12,\n",
       "        138,  32,  36, 196, 128, 193, 123, 177,  76, 155, 132,   1,  96,\n",
       "         46,  43, 150, 179, 134,  75,  44,  27, 106, 157, 116, 171,  71,\n",
       "        147,  40, 158, 199, 107], dtype=int32),\n",
       " 'cs': array([  0, 136,  55, 108,  28, 188,  99, 162,   5, 100, 161, 102, 140,\n",
       "         65,  66, 174,  82, 154,  71, 147,  17, 124, 191,  21, 186, 156,\n",
       "         29,  68,  88, 168,  50,  30,  89, 192,  37, 106,   1,  43,  46,\n",
       "         76,  75, 134,  44,  27, 179, 107, 155, 177,  36, 123,  34, 176,\n",
       "         32, 138, 196,  12,  95, 132, 143,  80,   6, 129,  72,  39, 135,\n",
       "         96, 113, 164, 187, 195, 109, 119, 175, 128, 193, 141, 144, 167,\n",
       "         11,  54, 120, 197,   7, 145,  64,   8, 169,  78,  42,  10, 160,\n",
       "        178, 189, 180,  16,  51,   9,  74, 151,  57,  60,  62, 101, 111,\n",
       "        133, 150, 185,  24,  84, 173,   2, 148, 153, 172, 182, 149,  15,\n",
       "         93,  19, 115,  61, 105, 117,  53, 194,  38, 127, 146, 199, 126,\n",
       "         23,  87,  41, 184,  98, 110,   4,  35,  67, 131,  59,  92,  18,\n",
       "         94,  81,  91,  47,  31, 190, 139, 152, 118, 130, 121, 142,  40,\n",
       "        158,  25,  79,  70, 104,  83,  63,  77, 170, 181, 103,  85,  73,\n",
       "        137,  13,  90, 114, 125, 165, 166,  56, 122, 159,  14,  20,  26,\n",
       "         52,  33,  45,  49,  69, 171, 198, 116, 157, 112,  22,  97,  86,\n",
       "        163,  48,  58,   3, 183], dtype=int32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_old_ol_to_new_ol[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol['cs'][51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HU:\\n', '0 => Tectum stratum periventriculars\\n', '1 => tectum stratum periventriculare => medial\\n', '2 => tectum stratum periventriculare => medial\\n', '3 => Tectum stratum periventriculars\\n', '4 => Tectum stratum periventriculars \\n', '5 => tectum stratum periventriculare => medial\\n', '6 => tectum stratum periventriculare => medial\\n', '7 => Tectum stratum periventriculars\\n', '8 => Tectum stratum periventriculars\\n', '9 => tectum stratum periventriculare => medial\\n', '10 => Tectum stratum periventriculars\\n', '11 => Tectum stratum periventriculars\\n', '12 => tectum stratum periventriculare => medial\\n', '13 => Tectum stratum periventriculars\\n', '14 => Tectum stratum periventriculars\\n', '15 => Tectum stratum periventriculars\\n', '16 => Tectum stratum periventriculars\\n', '17 => Tectum stratum periventriculars\\n', '!   18 => Diencephalon and midbrain cluster => sparse activity !\\n', '20 => Tectum stratum periventriculars\\n', '21 => tectum stratum periventriculare => medial\\n', '22 => tectum stratum periventriculare => lateral\\n', '23 => Tectum stratum periventriculars\\n', '24 => tectum stratum periventriculare => lateral\\n', '28 => tectum stratum periventriculare => medial   <=> 145\\n', '29 => Tectum stratum periventriculars\\n', '31 => tectum neuropil\\n', '32 => torus semicircular\\n', '!   33 => lateral tegmentum \\n', '34 => lateral torus semicircular\\n', '35 => torus semicircularis\\n', '37 => tectum stratum periventriculare\\n', '38 => Tectum stratum periventriculars\\n', '39 => pretectum + dorsal thalamus\\n', '41 => big caudal cluster in mid and forebrain\\n', '42 => cerebellum Vglut2 enriched\\n', '43 => torus semicircularis\\n', '45 => nMLF (tegmentum) \\n', '46 => nMLF + nIII + nIV\\n', '47 => pretectum + AF9\\n', '48 => Gad1b cluster => many neurons not so clear \\n', '!   52 => medial caudal hindbrain cluster\\n', '53 => isl1 cluster ???? (small number of neurons)\\n', '!   54 => left ( nMLF ; nIII ; nIV ; hindbrain stripes)\\n', '55 => valvula cerebellum => Gad1b\\n', '56 => neuromodulation ? Raphe + Gad1b + volut2\\n', '57 => cerebellum\\n', '58 => Tectrum stratum periventriculars\\n', '59 => Tectrum stratum periventriculars\\n', '60 => Tectrum stratum periventriculars\\n', '61 => Tectrum stratum periventriculars\\n', '62 => tectum stratum periventriculare => medial\\n', '63 => Tectrum stratum periventriculars\\n', '64 => Tectrum stratum periventriculars\\n', '65 => Tectum stratum periventriculars\\n', '66 => Tectrum stratum periventriculars\\n', '67 => Tectrum stratum periventriculars \\n', '68 => Tectrum stratum periventriculars\\n', '73 => cerebellar vglut2 enriched area  + eminentia granular (granular cells ???)\\n', '75 => small but very active\\n', '76 => Tectrum stratum periventriculars \\n', '80 => tectum stratum periventriculare => medial\\n', '81 => Tectrum stratum periventriculars\\n', '82 => Tectrum stratum periventriculars\\n', '83 => Tectrum stratum periventriculars \\n', '84 => Tectrum stratum periventriculars \\n', '85 => Tectrum stratum periventriculars \\n', '86 => Tectrum stratum periventriculars \\n', '87 => Tectum stratum periventriculars\\n', '88 => Tectum stratum periventriculars\\n', '89 => Tectrum stratum periventriculars \\n', '90 => Tectum stratum periventriculars\\n', '!   91 => medial hindbrain stripes (especially looks interesting)\\n', '!   92 => medial hindbrain stripes\\n', '!   93 => big lateral cluster perhaps related to strong tail flip ???\\n', '94 => oscillator\\n', '!   95 => medial hindbrain stripes\\n', '!!   96 => small number of neurons => interesting bimodal activity\\n', '!   98 => VII facial motor  and ovtovolateralis effent neurons => Interesting !!!\\n', '!!   99 => oscillator\\n', '!!   100 => statoacoustic ganglion; tangential vestibular nucleus; RS vestibular population => slow decay activity \\n', '!!   101 => statoacoustic ganglion; tangential vestibular nucleus; =>  slow decay activity  == 87\\n', '102 => saccarde circuit\\n', '104 => small clearly defined hindbrain cluster MidD2 => what is this?\\n', '108 => nMLF and hindbrain cluster\\n', '!   110 => two clusters around ears \\n', '111 => many neurons but symmetric in hindbrain\\n', '!!   112 => nV + Isl1 motor neurons + Spinal cord + nice clusters at midbrain-hindbrain boundary  => related to behaviour?\\n', '!   114 => similar to 68 but less neurons and similar activity\\n', '!   116 => Spinal cord and well defined small and symmetric hindbrain regions\\n', '!   117 => Spinal cord ; RS neurons ; two symmetric nice clusters ; purkinje cells ? \\n', '118 => oscillator ?\\n', '!   124 => blue midbrain + red hindbrain\\n', '125 => nIII\\n', '126 => == 58\\n', '!!   127 => medial vestibular nucleus + oculomotor neurons? + preteritum ?\\n', '128 => interesting two cluster pattern\\n', '!   133 => Gad1b stripe 3 ; Glyt stripe 3; Vglut2 stripe 3\\n', '134 => nV Trigeminal Motorneurons ; VII facial motor and octavolateralis efferent neurons; olig2 stripe\\n', '!   135 => Gad1b stripe 2 ; Vglut2 stripe 2\\n', '!   140 => Corpus Cerebelli ; Cerebellar Vglut2  => granular cells ?\\n', '!!   141 => nice symmetric cerebellar cluster\\n', '143 => vagal motor neurons + vagal ganglia !\\n', '150 => cerebellum (valvular + corpus )=> nice dense small cluster ()\\n', '152 => vagus motor neurons + vagus ganglion == 64\\n', '!   153 => brain wide cluster from Diencephalon to midbrain to hindbrain\\n', '!   154 => vagus motor neurons + vagus ganglion\\n', '158 => diffuse\\n', '159 => oscillator ?  + IPN\\n', '160 => Valvula cerebelli + nIV\\n', '161 => oscillator ?\\n', '163 => nIII -> saccarde circuit  ?\\n', '!!!   164 => left right symmetry between inhibitory and exitatory cluster\\n', '168 => nIII -> saccarde circuit ?\\n', '174 => statoacoustic ganglion\\n', '!   175 => diffuse But => symmetric blue and red organisation\\n', '176 => olfactory bulb\\n', '!!   177 => Telencephalon: Pallium ; Subpallium + IPN ?\\n', '!!   178 => Telencephalon + Hindbrain cluster => similar but less defined as 158\\n', '180 => diffuse but symmetric\\n', '183 => clear cluster in rhombencephalon\\n', '!   185 => asymmetric cluster\\n', '!   186 => as 121 but mirror symmetric to the mid plane\\n', '187 => torus semicircularis\\n', '188 =>  torus semicircularis\\n', '189 => torus semicircularis\\n', '190 => torus semicircularis\\n', '!!   191 => lobus caudalis cerebelli + contralateral cluster in rhombomere 2\\n', '192 => locus coreueleus (noradrenergic nucleus) + torus semicirucalis + cerebellum\\n', '!   193 => as 128 but more diffuse\\n', '194 => diffuse\\n', '197 => broadly distributed\\n', '!   198 => small active double cluster => not sure what this is\\n', '!   199 => symmetric cerebellum; nIV ; hypothalamus and others\\n', '\\n', '\\n', '\\n', '\\n', 'ToDo \\n', 'group all Tectum stratum periventriculars in one plot with different colours (give number of HU)   ~ N = fifty  or in one pdf\\n', 'group all torus semicircular HU in one plot with different colours (give number of HU): 32, 34, 35, 43,  187, 188, 190, 190,  192\\n', 'make a group of HU with combined red and blue receptive fields: ! 48, ! 56,  ! 72, 77, 78,  113, 122, 124, 132, ! 143, 175\\n', 'group all raphe clusters\\n', 'group all cerebellum clusters: 42,  55, 57, 73,  ! 140, !! 141, 150, 160, !! 191, 192, ! 199\\n', 'group all spinal chord cluster: 53,  116, 117,  124\\n', 'Oscillator / saccarde circuit: 94, 99,  161, 163,  167\\n', 'group hindbrain stripe HUs: 54, 91, 92, 94, 95, 119, 121,  122, 133, 134, 135, 143, 169,  170, 171, 172, 173\\n', 'group vestibular cluster:  100, 101,  127\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "indiv_units = True\n",
    "new_content = []\n",
    "new_lines_dict = {}\n",
    "new_groups_dict = {}\n",
    "for i_line, line in enumerate(content):\n",
    "    # line = line.rstrip()  #\\n\n",
    "    if i_line == 0:\n",
    "        new_content.append(line) # title \n",
    "    elif indiv_units:  # list of individual units\n",
    "        split_line = line.split('=>')\n",
    "        hu_index = split_line[0].lstrip('!').strip(' ')\n",
    "        attention = split_line[0].rstrip(' ').rstrip(hu_index)\n",
    "        new_hu_index = translation_old_ol_to_new_ol[int(hu_index)]\n",
    "        new_line = attention + ' ' + str(new_hu_index) + ' ' +  ''.join(['=>' + x for x in split_line[1:]])  # replace with new index\n",
    "        new_line = new_line.lstrip(' ')\n",
    "        new_lines_dict[new_hu_index] = new_line  # save in dict to later to alphabetically\n",
    "#         print(line, new_line)\n",
    "        if int(hu_index) == 199:  # last one (hard coded)\n",
    "            indiv_units = False\n",
    "    else: # groupings at bottom of file\n",
    "        line_split = line.split(':')\n",
    "        if len(line_split) == 1:\n",
    "            new_groups_dict[i_line] = line\n",
    "            continue  # nothing here \n",
    "        \n",
    "        else:\n",
    "            assert len(line_split) == 2\n",
    "            info_group = line_split[0]\n",
    "            old_hu_list = line_split[1].split(', ')  # make sure all HUs are separated by comma space\n",
    "            new_hu_list = old_hu_list.copy()\n",
    "            tmp_arr_new_hu = np.zeros(len(new_hu_list))  # used for new alphabetical sorting \n",
    "            for i_hu, old_hu in enumerate(old_hu_list):\n",
    "                old_hu_index = int(''.join(i for i in old_hu if i.isdigit()))  # only get digits\n",
    "                new_hu_list[i_hu] = new_hu_list[i_hu].replace(str(old_hu_index), \n",
    "                                                              str(translation_old_ol_to_new_ol[old_hu_index]))  # replace, so !! are kept intact\n",
    "                tmp_arr_new_hu[i_hu] = translation_old_ol_to_new_ol[old_hu_index]\n",
    "            sorted_new_hu_inds = np.argsort(tmp_arr_new_hu)  # determine new sorting\n",
    "            sorted_new_hu_list = [new_hu_list[x].rstrip('\\n') for x in sorted_new_hu_inds]  # like this, so !! are maintained\n",
    "            new_line = info_group + ': ' + ', '.join(sorted_new_hu_list) + '\\n'  # remake \n",
    "            new_groups_dict[i_line] = new_line\n",
    "#             print(info_group, old_hu_list, new_hu_list, new_line)\n",
    "\n",
    "# for i_line, new_line in new_lines_dict.items():\n",
    "\n",
    "for i_line in range(200):  # add alphabetically \n",
    "    if i_line in new_lines_dict.keys():\n",
    "        new_content.append(new_lines_dict[i_line])\n",
    "for i_line, new_line in new_groups_dict.items():\n",
    "    new_content.append(new_line)\n",
    "\n",
    "print(new_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to new file\n",
    "# with open(os.path.join(new_dir, new_annot_file), 'w') as new_f:\n",
    "#     for line in new_content:\n",
    "#         new_f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## do the few references to other HUs in the individual part by hand\n",
    "translation_old_ol_to_new_ol[128]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
